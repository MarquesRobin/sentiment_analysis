{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7a4b344-7278-40ae-ac34-c8b00a5ead8c",
   "metadata": {},
   "source": [
    "# **Mini Project 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ab955a-3c85-4b17-bbd4-25003c4bcc00",
   "metadata": {},
   "source": [
    "0. Requirements:\n",
    "   \n",
    "   If you do not have the following packages installed, run the command below to install them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "088818d9-da0f-4444-8254-0517b30c0344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install scikit-learn\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install nltk\n",
    "# !pip install codecarbon\n",
    "# !pip install shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67299e6e-3164-4d60-856a-d67b172cc449",
   "metadata": {},
   "source": [
    "1. Data Preparation:\n",
    "   \n",
    "    Goal: Load and inspect the IMDb dataset containing movie reviews labeled with positive and negative sentiments.(https://ai.stanford.edu/%7Eamaas/data/sentiment/)\n",
    "    \n",
    "    Task: Read the dataset, store the reviews and their associated sentiments, and explore the dataset to understand its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac27db4f-7b71-41a4-8d94-1a92cacd5c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import shap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords # Importe la liste des \"stop words\" (mots vides) de la bibliothèque NLTK (Natural Language Toolkit)\n",
    "from nltk.stem import PorterStemmer # Importe la classe PorterStemmer de NLTK. Le stemming est un processus qui consiste à réduire les mots à leur racine (stem)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from codecarbon import EmissionsTracker\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd23c874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fonctions de chargement et d'affichage des données\n"
     ]
    }
   ],
   "source": [
    "# --- Fonction de chargement des données ---\n",
    "\n",
    "def load_movie_reviews(data_folder):\n",
    "    \"\"\"\n",
    "    Charge les critiques de films à partir d'une structure de dossiers\n",
    "    (pos/ et neg/) et les renvoie sous forme de DataFrame Pandas.\n",
    "\n",
    "    Args:\n",
    "        data_folder: Le chemin vers le dossier principal contenant les\n",
    "                     sous-dossiers 'pos' et 'neg'.\n",
    "\n",
    "    Returns:\n",
    "        Un DataFrame Pandas avec deux colonnes : 'review' (texte de la critique)\n",
    "        et 'sentiment' ('pos' ou 'neg').\n",
    "        Retourne None si une erreur se produit.\n",
    "    \"\"\"\n",
    "    reviews = []\n",
    "    sentiments = []\n",
    "\n",
    "    for sentiment in ['pos', 'neg']:\n",
    "        folder_path = os.path.join(data_folder, sentiment)  # Chemin complet vers pos/ ou neg/\n",
    "\n",
    "        if not os.path.isdir(folder_path):\n",
    "            print(f\"Erreur : Le dossier '{folder_path}' n'existe pas.\")\n",
    "            return None\n",
    "\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith(\".txt\"):  # Traiter seulement les fichiers .txt\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:  # 'utf-8' pour gérer les accents\n",
    "                        review_text = f.read()\n",
    "                        reviews.append(review_text)\n",
    "                        sentiments.append(sentiment)\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"Erreur: Fichier '{file_path}' introuvable (improbable).\")\n",
    "                    return None  # Tu peux choisir de continuer ou d'arrêter ici\n",
    "                except Exception as e:\n",
    "                    print(f\"Erreur lors de la lecture de '{file_path}': {e}\")\n",
    "                    return None\n",
    "\n",
    "    # Crée le DataFrame Pandas\n",
    "    df = pd.DataFrame({'review': reviews, 'sentiment': sentiments})\n",
    "    return df\n",
    "\n",
    "# --- Fonctions d'affichage ---\n",
    "\n",
    "def display_dataframe_info(df, num_reviews=1, example_index=0):\n",
    "    \"\"\"Affiche des informations complètes sur le DataFrame, y compris des exemples.\n",
    "\n",
    "    Args:\n",
    "        df: Le DataFrame Pandas à afficher.\n",
    "        num_reviews: Le nombre de premières lignes à afficher (head).\n",
    "        example_index: L'indice de la critique d'exemple à afficher.\n",
    "    \"\"\"\n",
    "    if df is None or df.empty:\n",
    "        print(\"Le DataFrame est vide ou None.\")\n",
    "        return\n",
    "\n",
    "    print(df.head(num_reviews))  # Affiche les n premières lignes\n",
    "    print(\"-\" * 20)\n",
    "    print(df.info())  # Informations générales (types, colonnes, etc.)\n",
    "    print(\"-\" * 20)\n",
    "    print(df['sentiment'].value_counts())  # Nombre de critiques par sentiment\n",
    "    print(\"-\" * 20)\n",
    "\n",
    "    if example_index < len(df):\n",
    "        print(f\"\\nExemple de critique (index {example_index}):\")\n",
    "        print(df['review'][example_index])\n",
    "        print(\"Sentiment associé:\", df['sentiment'][example_index])\n",
    "    else:\n",
    "        print(f\"L'index d'exemple {example_index} est en dehors des limites du DataFrame.\")\n",
    "\n",
    "def display_first_reviews(df, num_reviews=5):\n",
    "    \"\"\"Affiche les premières lignes (head) du DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df: Le DataFrame Pandas à afficher.\n",
    "        num_reviews: Le nombre de premières lignes à afficher.\n",
    "    \"\"\"\n",
    "    if df is None or df.empty:\n",
    "        print(\"Le DataFrame est vide ou None.\")\n",
    "        return\n",
    "\n",
    "    print(df.head(num_reviews))\n",
    "\n",
    "print(\"\\nFonctions de chargement et d'affichage des données\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c476fb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données d'entraînement :\n",
      "                                              review sentiment\n",
      "0  Although I didn't like Stanley & Iris tremendo...       pos\n",
      "1  I'm sure that not many people outside of Austr...       pos\n",
      "2  I gave this film 10 not because it is a superb...       pos\n",
      "3  this movie is such a moving, amazing piece of ...       pos\n",
      "4  Bogdonovich's (mostly) unheralded classic is a...       pos\n",
      "--------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6250 entries, 0 to 6249\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     6250 non-null   object\n",
      " 1   sentiment  6250 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 97.8+ KB\n",
      "None\n",
      "--------------------\n",
      "sentiment\n",
      "pos    3125\n",
      "neg    3125\n",
      "Name: count, dtype: int64\n",
      "--------------------\n",
      "\n",
      "Exemple de critique (index 0):\n",
      "Although I didn't like Stanley & Iris tremendously as a film, I did admire the acting. Jane Fonda and Robert De Niro are great in this movie. I haven't always been a fan of Fonda's work but here she is delicate and strong at the same time. De Niro has the ability to make every role he portrays into acting gold. He gives a great performance in this film and there is a great scene where he has to take his father to a home for elderly people because he can't care for him anymore that will break your heart. I wouldn't really recommend this film as a great cinematic entertainment, but I will say you won't see much bette acting anywhere.\n",
      "Sentiment associé: pos\n"
     ]
    }
   ],
   "source": [
    "# Charger les données pour l'entraînement\n",
    "data_directory = \"database_less/train\"  \n",
    "movie_reviews_train_df = load_movie_reviews(data_directory)\n",
    "\n",
    "# Vérifier le contenu du DataFrame d'entraînement\n",
    "print(\"Données d'entraînement :\")\n",
    "display_dataframe_info(movie_reviews_train_df, num_reviews=5, example_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "904188b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Données de test :\n",
      "                                              review sentiment\n",
      "0  This was absolutely one of the best movies I'v...       pos\n",
      "1  As others that have commented around the web.....       pos\n",
      "2  The plot of this movie is set against the most...       pos\n",
      "3  The cinematography is the film's shining featu...       pos\n",
      "4  (This has been edited for space)<br /><br />Ch...       pos\n",
      "--------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6250 entries, 0 to 6249\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     6250 non-null   object\n",
      " 1   sentiment  6250 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 97.8+ KB\n",
      "None\n",
      "--------------------\n",
      "sentiment\n",
      "pos    3125\n",
      "neg    3125\n",
      "Name: count, dtype: int64\n",
      "--------------------\n",
      "\n",
      "Exemple de critique (index 0):\n",
      "This was absolutely one of the best movies I've seen. <br /><br />Excellent performances from a marvelous A-List cast that will move you from smiles to laughter to tears and back.<br /><br />I couldn't help but care about the characters. Ms. Merkerson will blow you away, as will the young man playing the young lead.<br /><br />I also thought that the set design was top-rate. The viewer is really placed inside each era as it's presented. <br /><br />The music is a blast, too. Nice selections to represent mood, time and place. The blind blues man is stereotypic but he delivers some great songs. <br /><br />This is a great story that will survive many repeated viewings. Take the time to watch it!\n",
      "Sentiment associé: pos\n"
     ]
    }
   ],
   "source": [
    "# === MAIN ===\n",
    "\n",
    "# Charger les données pour les tests\n",
    "data_directory = \"database_less/test\"\n",
    "movie_reviews_test_df= load_movie_reviews(data_directory)\n",
    "\n",
    "# Vérifier le contenu du DataFrame de test\n",
    "print(\"\\nDonnées de test :\")\n",
    "display_dataframe_info(movie_reviews_test_df, num_reviews=5, example_index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d51ac0-9bee-470f-83d8-a124ad0aa846",
   "metadata": {},
   "source": [
    "2. Text Preprocessing:\n",
    "   \n",
    "    Goal: Clean and preprocess the text data to remove noise and prepare it for analysis.\n",
    "    \n",
    "    Task: Remove unnecessary characters (e.g., HTML tags, punctuation), convert text to lowercase, and process words by removing stop words and stemming/lemmatizing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ebde4d1-aa98-450a-b972-ef9a0c2f555a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fonction de nettoyage des critiques d'entraînement\n"
     ]
    }
   ],
   "source": [
    "# --- Fonctions de nettoyage des données ---\n",
    "\n",
    "def remove_html_bs(text): # fonction pour supprimer les balises HTML\n",
    "    \"\"\"Supprime les balises HTML (avec BeautifulSoup).\"\"\"\n",
    "    try:\n",
    "        soup = BeautifulSoup(text, \"html.parser\")\n",
    "        return soup.get_text(separator=\" \")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du nettoyage HTML : {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def remove_special_characters(text): # fonction pour supprimer les caractères spéciaux\n",
    "    \"\"\"Supprime les caractères spéciaux et la ponctuation.\"\"\"\n",
    "    pattern = r\"[^a-zA-ZÀ-ÖØ-öø-ÿ0-9\\s]\"\n",
    "    cleaned_text = re.sub(pattern, \" \", text)\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "    return cleaned_text\n",
    "\n",
    "def convert_to_lowercase(text): # fonction pour convertir les caractères en minuscules\n",
    "    \"\"\"Convertit une chaîne de caractères en minuscules.\"\"\"\n",
    "    return text.lower()\n",
    "\n",
    "def remove_stopwords(text): # fonction pour supprimer les mots vides\n",
    "    \"\"\"Supprime les mots vides (stop words) en utilisant NLTK.\"\"\"\n",
    "    stop_words = set(stopwords.words('english'))  # Important: Utilise 'english'\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return \" \".join(filtered_words) # Reconstruit la phrase\n",
    "\n",
    "def apply_stemming(text): # fonction pour appliquer le stemming\n",
    "    \"\"\"Applique le stemming (PorterStemmer) de NLTK.\"\"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    words = text.split()\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return \" \".join(stemmed_words)\n",
    "\n",
    "def apply_lemmatization(text): # fonction pour appliquer la lemmatisation\n",
    "    \"\"\"Applique la lemmatisation avec WordNetLemmatizer de NLTK.\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = text.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return \" \".join(lemmatized_words)\n",
    "\n",
    "def clean_reviews(df):\n",
    "    \"\"\"\n",
    "    Nettoie un DataFrame de critiques (HTML, caractères spéciaux, minuscules, stop words, stemming/lemmatization).\n",
    "    Modifie le DataFrame en place.\n",
    "    \"\"\"\n",
    "    # Vérifie si le DataFrame est vide\n",
    "    if df.empty:\n",
    "        print(\"Erreur : Le DataFrame est vide. Impossible de le nettoyer.\")\n",
    "        return\n",
    "\n",
    "    # Vérifie si la colonne 'review' existe\n",
    "    if 'review' not in df.columns:\n",
    "        print(\"Erreur : La colonne 'review' est absente du DataFrame.\")\n",
    "        return\n",
    "\n",
    "    # Applique les fonctions de nettoyage, en séquence\n",
    "    df['review'] = df['review'].apply(remove_html_bs)\n",
    "    df['review'] = df['review'].apply(remove_special_characters)\n",
    "    df['review'] = df['review'].apply(convert_to_lowercase)\n",
    "    df['review'] = df['review'].apply(remove_stopwords)\n",
    "    df['review'] = df['review'].apply(apply_stemming)  # Optionnel : Stemming\n",
    "    df['review'] = df['review'].apply(apply_lemmatization) # Optionnel : Lemmatization\n",
    "\n",
    "    # La fonction ne retourne rien, car elle modifie le DataFrame directement\n",
    "\n",
    "print(\"\\nFonction de nettoyage des critiques d'entraînement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fa515c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5885/195796097.py:6: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, \"html.parser\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critiques de test nettoyées :\n",
      "                                              review sentiment\n",
      "0  absolut one best movi seen excel perform marve...       pos\n",
      "1  other comment around web 130 pilot coast guard...       pos\n",
      "2  plot movi set terribl war histori mankind viol...       pos\n",
      "3  cinematographi film shine featur park realli k...       pos\n",
      "4  edit space chan wook park new film complex fil...       pos\n"
     ]
    }
   ],
   "source": [
    "# === MAIN ===\n",
    "\n",
    "if movie_reviews_test_df is not None:\n",
    "    clean_reviews(movie_reviews_test_df)  # Nettoyage des critiques de test\n",
    "    print(\"Critiques de test nettoyées :\")\n",
    "    display_first_reviews(movie_reviews_test_df, num_reviews=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dba903d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5885/195796097.py:6: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, \"html.parser\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critiques d'entraînement nettoyées :\n",
      "                                              review sentiment\n",
      "0  although like stanley iri tremend film admir a...       pos\n",
      "1  sure mani peopl outsid australia ever heard le...       pos\n",
      "2  gave film 10 superbl consist movi pure abil ev...       pos\n",
      "3  movi move amaz piec work saw theater came 13 r...       pos\n",
      "4  bogdonovich mostli unherald classic film unlik...       pos\n"
     ]
    }
   ],
   "source": [
    "# === MAIN ===\n",
    "\n",
    "if movie_reviews_test_df is not None:\n",
    "    clean_reviews(movie_reviews_train_df)  # Nettoyage des critiques d'entraînement\n",
    "    print(\"Critiques d'entraînement nettoyées :\")\n",
    "    display_first_reviews(movie_reviews_train_df, num_reviews=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbff49f-7177-4dad-8138-a08ec1420c59",
   "metadata": {},
   "source": [
    "3. Feature Extraction:\n",
    "\n",
    "    Goal: Transform the cleaned text into numerical features for machine learning.\n",
    "   \n",
    "    Task: Use a vectorization technique such as TF-IDF to convert the text into a numerical matrix that captures the importance of each word in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b77c2734-32dc-4899-bb4d-85140baecd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 3: Feature Extraction \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b244b9d2-245c-4f5c-a9f1-cd97084d2aab",
   "metadata": {},
   "source": [
    "4. Model Training:\n",
    "\n",
    "    Goal: Train a machine learning model to classify reviews based on their sentiment.\n",
    "    \n",
    "    Task: Split the dataset into training and testing sets, train a Logistic Regression model, and evaluate its performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d389d0b4-232a-4ce4-8b19-c311f6037058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 4: Model Training \n",
    "\n",
    "# TASK 8: Track emissions during model training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e805c3d1-f7b0-4a88-9eec-38244f446d37",
   "metadata": {},
   "source": [
    "5. Model Evaluation:\n",
    "\n",
    "    Goal: Assess the performance of your model using appropriate metrics.\n",
    "    \n",
    "    Task: Evaluate precision, recall, and F1-score of the Logistic Regression model. Use these metrics to identify the strengths and weaknesses of your system. Visualize the Confusion Matrix to better understand how well the model classifies positive and negative reviews. Additionally, test the model with a new review, preprocess it, make a prediction, and display the result. Example: test it with a new review such as:\n",
    "    \"The movie had great visuals, but the storyline was dull and predictable.\" The expected output might be: Negative Sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce51fa9b-37e6-4683-a897-0e457cedef7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 5: Model Evaluation \n",
    "\n",
    "# Classification Report\n",
    "\n",
    "# Confusion Matrix\n",
    "\n",
    "# Plot the Confusion Matrix\n",
    "\n",
    "# Test with a new review\n",
    "review = \"The movie had great visuals but the storyline was dull and predictable.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef444de-e61a-43c8-81a1-4a82acf787f2",
   "metadata": {},
   "source": [
    "6. Hyperparameter Tuning:\n",
    "\n",
    "    Goal: Optimize your Logistic Regression model by tuning its hyperparameters.\n",
    "   \n",
    "    Task: Use an optimization method to find the best parameters for your model and improve its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8dac172-a9b4-496c-b89c-59dbf05e2ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 6: Hyperparameter Tuning \n",
    "\n",
    "# TASK 8: Track emissions during Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd78c01-5d86-48b6-ad27-a31ab8cb060b",
   "metadata": {},
   "source": [
    "7. Learning Curve Analysis:\n",
    "\n",
    "    Goal: Diagnose your model's performance by plotting learning curves.\n",
    "   \n",
    "    Task: Analyze training and validation performance as a function of the training set size to identify underfitting or overfitting issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f27b49a-3e3e-44ee-9215-79502caee218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 7: Learning Curve Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c754b47-0e39-4ee2-97a0-80e11275716e",
   "metadata": {},
   "source": [
    "9. Ethical Considerations and Explainability:\n",
    "\n",
    "    Goal: Discuss the ethics in using and deploying your AI-based solution by investigating and implementing suitable explainability methods.\n",
    "    \n",
    "    Task: Understanding how a machine learning model makes predictions is crucial for ensuring transparency, fairness, and accountability in AI deployment. One of the widely used techniques for model explainability is SHAP (SHapley Additive exPlanations), which helps determine how much each feature (word) contributes to a prediction.\n",
    "    In this task, you will use SHAP to analyze the impact of individual words on sentiment classification. This will allow you to visualize which words increase or decrease the probability of a positive or negative sentiment prediction. Additionally, discuss key aspects such as potential biases in the model, fairness in outcomes, and accountability in AI decision-making. You can find more information here: https://shap.readthedocs.io/en/latest/generated/shap.Explanation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a6bcdfe-5c11-4bfe-af4a-72d53c9925ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 9: Ethical Considerations & Explainability\n",
    "\n",
    "# Show SHAP summary plot with proper feature names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9633197-d745-4879-acd9-c4ed306dda03",
   "metadata": {},
   "source": [
    "10. Deployment Considerations for Embedded Systems:\n",
    "\n",
    "    Goal: Optimize and convert the trained logistic regression model for deployment on embedded systems like Arduino\n",
    "    \n",
    "    Task: To deploy the trained logistic regression model on a resource-constrained embedded system like an Arduino, we must optimize and convert the model into a format suitable for execution in an environment with limited memory and processing power. Since embedded systems do not support direct execution of machine learning models trained in Python, we extract the model’s learned parameters—namely, the weights and bias—after training. These parameters are then quantized to fixed-point integers to eliminate the need for floating-point calculations, which are inefficient on microcontrollers.\n",
    "    Once quantization is applied, we generate a C++ .h header file containing the model’s coefficients and bias, formatted in a way that allows direct use within an Arduino sketch. The final model is optimized to perform inference using integer arithmetic, making it both lightweight and efficient for deployment on microcontrollers. You can find more information here: https://medium.com/@thommaskevin/tinyml-binomial-logistic-regression-0fdbf00e6765"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57c6df56-5cd7-4894-8b19-321c37bb3427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 10: Deployment Considerations (Model Quantization & Export for Arduino)\n",
    "# Extract weights and bias from the trained logistic regression model\n",
    "\n",
    "# Apply quantization (convert to fixed-point representation)\n",
    "\n",
    "# Generate C++ header file for Arduino\n",
    "\n",
    "# Save the header file\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GEI1092",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
